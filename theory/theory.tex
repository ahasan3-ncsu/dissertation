\chapter{Theoretical Background}

\section{Molecular Dynamics}

Molecular dynamics (MD) is a computer simulation technique
where the time evolution of a set of interacting atoms
is calculated using equations of motion.
The laws of classical mechanics, such as Newton's second law,
is followed in this technique.
For example, in a closed system consisting of $N$ atoms,
the force acting on an atom $i$ is
\begin{align}
	\bm{F}_i = m \bm{a}_i = m \frac{d^2 \bm{r}_i}{dt^2}
\end{align}

This force is a result of the interactions of atom $i$
with all the other atoms in the system.
If the force acting on an atom is known, its movement can be predicted
given the initial position and velocity \cite{ercolessi}.
We can derive these forces
by computing the gradients of the potential energy of the system
with respect to atomic displacements.
\begin{align}
	\bm{F}_i = - \nabla_{\bm{r}_i} V(\bm{r}_1,\ldots,\bm{r}_N)
\end{align}

The potential energy of the system actually depends on the interaction
between the subatomic particles in the atoms.
Thus, the true interatomic interactions are quantum mechanical in nature.
It is not known whether the interactions described by
the Schr\"odinger equation or Dirac equation for all subatomic particles
could be cast into an analytical functional form
to describe the interactions between atoms.
Thus, all descriptions of interatomic potentials are approximations.

In \textit{ab initio} MD (AIMD), interatomic forces are calculated on-the-fly
using quantum mechanicaly methods, typically density functional theory (DFT).
Forces are obtained from the electronic wavefunction
computed at each time step using DFT,
while assuming electrons adapt instantaneously compared to nuclei positions.
This is known as Born-Oppenheimer approximation.
Although calculations from first-principles are accurate,
they are computationally expensive and sometimes infeasible for certain tasks.

Finding a practical and efficient description of the potential energy,
albeit approximate, is the crux of MD.
The classical interatomic potentials try to approximate
the true nature of atomic interactions at the expense of accuracy,
the advantage being reduced computational cost \cite{marx}.
Interatomic potentials can be either parametric or non-parametric.
We will discuss the differences between them in the following section.

After defining the interactions among atoms through a potential,
new positions and velocities of atoms can be calculated using time integration.
Velocity-Verlet is the most commonly used integration scheme in MD
\cite{verlet, tuckerman}.
This allows the simulated systems to evolve in time,
which in turn provides insight into the behavior of complex atomic systems.

MD simulations are mainly done in the microcanonical ensemble.
However, in many situations,
the simulated system needs to have a constant temperature.
Among many methods introduced to control the temperature in a MD simulation,
the Nos\'e-Hoover thermostat is the most popular one \cite{hoover}.

\section{Interatomic Potential}

% TODO: citation needed
Interatomic potentials come in different forms
to accomodate different physical motivations.
Historically, most interatomic potentials could be described as "parametric",
since they are developed with a fixed number of physical terms and parameters.
In non-parametric potentials,
the total number of terms and parameters are flexible.
This allows systematic optimization of potentials
using complex local neighbor descriptors
and separate mappings to predict different system properties.
Even though the non-parametric potentials can be more accurate,
the lack of physical meaning behind the parameters
can make justification of extrapolation and uncertainty quantification harder.

The simplest parametric interatomic potential
would only consider pairwise interactions between atoms,
using pairwise potential function $\phi_{\alpha\beta}$
between atom types $\alpha$ and $\beta$.
These two-body (pairwise) potentials are poor for metallic systems.
The embedded-atom method (EAM) overcomes this problem
by adding an embedding energy term to the pairwise potential
\cite{daw1984eam, daw1993eam}.
In EAM, the potential energy $V_i$ of an atom $i$ is given by
\begin{align}
	V_i
	= \frac{1}{2} \sum_{j \ne i} \phi_{\alpha\beta} (r_{ij})
		+ F_{\alpha} \bigg( \sum_{j \ne i} \rho_{\beta} (r_{ij}) \bigg)
\end{align}
where $r_{ij}$ is the distance
between atom $i$ of type $\alpha$ and neighbors $j$ of type $\beta$,
$\rho_{\beta}$ is the contribution to the electro charge density
from atom $j$ at the location of atom $i$,
and $F_{\alpha}$ is an embedding function that represents
the energy required to place atom $i$ into the electron cloud.

% TODO: citation needed
The non-parametric potentials are often referred to
as machine-learned interatomic potentials (MLIPs).
While non-parametric models are especially suitable for the application of ML,
it is to be noted that
parametric potentials can also be optimized using machine learning,
The potential energy of a system in an MLIP is written as
\begin{align}
	V_{tot}
	= \sum_i V_i (\bm{q}_i)
\end{align}
where $\bm{q}_i$ is a mathematical representation
of the atomic environment surrounding the atom $i$,
commonly known as the descriptor.
$V_i$ is a machine-learning model that provides energy prediction
based on the descriptor.
An MLIP requires a robust descriptor
that maintains certain physical symmetries,
and a suitable machine learning framework for the descriptor.

\subsection{Angular Dependent Potential}

% TODO: why ADP?

The angular dependent potential (ADP) formalism
is a generalization of the EAM type potential.
The potential energy $V_i$ of an atom $i$ in ADP is given by
\begin{align}
	V_i
	&= \frac{1}{2} \sum_{j \ne i} \phi_{\alpha\beta} (r_{ij})
		+ F_{\alpha} \bigg( \sum_{j \ne i} \rho_{\beta} (r_{ij}) \bigg)
		+ \frac{1}{2} \sum_{s} (\mu_i^s)^2
		+ \frac{1}{2} \sum_{s, t} (\lambda_i^{st})^2
		- \frac{1}{6} \sum_i \nu_i^2 \\
	\mu_i^s
	&= \sum_{j \ne i} u_{\alpha\beta} (r_{ij}) r_{ij}^s \\
	\lambda_i^{st}
	&= \sum_{j \ne i} w_{\alpha\beta} (r_{ij}) r_{ij}^s r_{ij}^t \\
	\nu_i
	&= \sum_s \lambda_i^{ss}
\end{align}
where $i$, $j$, $\alpha$, $\beta$, $\phi_{\alpha\beta}$, and $F_{\alpha}$
have the same definitions as in the EAM formalism.
Additionally, $s$ and $t = 1, 2, 3$ and refer to the Cartesian coordinates.
The $\mu$ and $\lambda$ terms represent dipole and quadrupole distortions
of the local atomic environment.
This formalism extends the EAM by introducing angular forces
as dipole and quadrupole moments.

\subsection{Moment Tensor Potential}

\section{Inverse Uncertainty Quantification}

Inverse uncertainty quantification (IUQ) is a process
to quantify uncertainties in the input parameters of a computer model,
such as DART, given experimental data.
IUQ is an essential step in computational model validation
because it provides a concrete and quantifiable measure of uncertainty
in model predictions
\cite{wu2018inverse, nagel2019bayesian, wu2021comprehensive}.
The concept of IUQ is in contrast to forward uncertainty quantification (FUQ),
which quantifies the uncertainty in the output of a computer model
given the input parameters.
FUQ is often used to predict the uncertainty in the results of a simulation,
while IUQ is used to quantify the uncertainty in the model itself.
IUQ is often used in engineering and scientific applications
where there is a high degree of uncertainty in the input parameters.
By quantifying the uncertainty in the input parameters,
IUQ can help to improve the accuracy and reliability
of the model predictions \cite{wu2021comprehensive, xie2024functional}.
